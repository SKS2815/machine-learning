{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TITLE OF PROJECT-\n",
        "Iris Flower Classification Using Logistic Regression**"
      ],
      "metadata": {
        "id": "v7fR8ymYl-7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Objective**\n",
        "To build a machine learning model that classifies iris flowers into three species (setosa, versicolor, virginica) based on their features (sepal length, sepal width, petal length, petal width).\n",
        "\n",
        "**2. Data Source**\n",
        "The Iris dataset from the UCI Machine Learning Repository.\n"
      ],
      "metadata": {
        "id": "TLBe4KpvmUa0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Import Library**"
      ],
      "metadata": {
        "id": "9-TzQUXKnBY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "umqCKjT-oi-K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Import Data**"
      ],
      "metadata": {
        "id": "o1xseMGfoxo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['species'] = iris.target\n",
        "\n",
        "# Map target numbers to species names\n",
        "species_map = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
        "df['species'] = df['species'].map(species_map)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "AlIfO1jCo314"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Describe Data**"
      ],
      "metadata": {
        "id": "_aDuPaDpo9oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Display summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "YWeBmBCHpEM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Data Visualisation**"
      ],
      "metadata": {
        "id": "d1El2it5pMxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair plot\n",
        "sns.pairplot(df, hue='species')\n",
        "plt.show()\n",
        "\n",
        "# Histograms\n",
        "df.hist(edgecolor='black', linewidth=1.2, figsize=(12, 8))\n",
        "plt.show()\n",
        "\n",
        "# Box plots\n",
        "df.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False, figsize=(12, 8))\n",
        "plt.show()\n",
        "\n",
        "# Heatmap of correlations (excluding the species column)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.drop('species', axis=1).corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QykgtnRjpQml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Data Reprocessing**"
      ],
      "metadata": {
        "id": "9j78P6KNpZUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature variables\n",
        "X = df.drop('species', axis=1)\n",
        "\n",
        "# Target variable\n",
        "y = df['species']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "VyOacKRrpdOZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Define Target Variable (y) and Feature Variables (X)**\n",
        "This step was handled in the Data Preprocessing section.\n"
      ],
      "metadata": {
        "id": "CxVvn1WDpfbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Train Test Split**"
      ],
      "metadata": {
        "id": "nLNiGtMUpmJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "szcck5sppvol"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Modelling**"
      ],
      "metadata": {
        "id": "-5HfCPoPpwlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "GNekt84rp2gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Model Evaluation**"
      ],
      "metadata": {
        "id": "d_LrxdaPp6nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(\"Confusion Matrix:\\n\", confusion_mat)\n"
      ],
      "metadata": {
        "id": "QoJxjTcxqCaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Prediction**"
      ],
      "metadata": {
        "id": "Ept5sG1tqD8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Predicting the species for a new data point\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2]]  # Example data point\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "prediction = model.predict(new_data_scaled)\n",
        "predicted_species = prediction[0]\n",
        "print(f\"Predicted species: {predicted_species}\")\n"
      ],
      "metadata": {
        "id": "nUPAzfKrqJ3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Explaination**"
      ],
      "metadata": {
        "id": "PMDeBcITqLPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explanation = f\"\"\"\n",
        "The Logistic Regression model achieved an accuracy of {accuracy:.2f} on the test set.\n",
        "The classification report and confusion matrix provide detailed insights into the model's performance.\n",
        "The model was able to classify the Iris species accurately based on the provided features.\n",
        "Some challenges faced during the project included ensuring proper data preprocessing and scaling of feature variables.\n",
        "Future improvements could involve experimenting with other classification algorithms and tuning hyperparameters to achieve better performance.\n",
        "\"\"\"\n",
        "print(explanation)\n"
      ],
      "metadata": {
        "id": "qUuJl7U0qT4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}